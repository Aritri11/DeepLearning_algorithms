Feed Forward Neural Network from Scratch

This repository provides a simple yet flexible implementation of the forward pass component of a feedforward neural networkâ€”entirely from scratch and without using libraries like TensorFlow or PyTorch.

Overview
-- This project offers an educational and practical implementation of the core forward propagation routine in fully-connected (dense) neural networks. 
-- It allows you to specify the network architecture, activation function, and input, helping to demystify the step-by-step computations inside a neural network model.

Features
** Pure Python implementation (optionally uses NumPy for efficiency)

** Customizable layer sizes and number of layers

** Choice of activation function per layer

** Random weight and bias initialization
